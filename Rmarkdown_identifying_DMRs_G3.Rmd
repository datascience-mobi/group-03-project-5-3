---
title: "Identifying DMRs"
author: "Leo Burmedi, Pierre De Marinis, Konstantin Fischer, Daniel Ãœrge"
date: "6/10/2019"
output:
  html_document: default
  word_document: default
---

# Introduction

> Differentially methylated regions (DMRs) ... 

### Annotation for naming dataframes and functions.

 Code      | Annotation
 --------- | ------------------------------------------------------------------
 g_[text]  | dataframe derived from the genes_data_frame dataset  
 p_[text]  | dataframe derived from the promoters_data_frame dataset 
 _Resource | resource dataset, includes the remaining rows after quality conrol with Ensembl ID, symbol and the fold change 
 _T        | dataframe, that is than used for the t-test, includes number of NAs (n), means (m), standard deviations (sd) for each row
i,j, y     | vectrors only used by function and loops
f_[text]   | function
_cov       | coverage values
_bed, _bet | beta values
_Mvalues   | dataset with all reamining genes/ promoters after QC, normalization and imputation


### Loading the data and naming the frames.
```{r, echo=TRUE} 
## Loading the dataframe and naming in input_data is neccesary first for the code to run threw properly. 
input_data <- readRDS("~/Heidelberg/Uni/FS4 2019/Bioinfo/AMLvsMono/AML_Mono_list.RDS")
genes_data_framexy <- input_data$genes
promoters_data_framexy <- input_data$promoters
cpgislands_data_frame <- input_data$cpgislands
tiling_data_frame <- input_data$tiling
remove(tiling_data_frame, cpgislands_data_frame, input_data)
```

> From these datasets only the genes and the promoters will be relevant for the analysis because thay contain the highest amount of relevant information for us.  

# Quality control

> The goal of Qualtity control is to make the dataset as suited as possible for the analyis. This includes: removing uncessary variables, getting rid NAs, removing information that can produce fallicous results.

### Removing chromosome X and Y.

> Chromosome X is removed because it can be hypermethylated by female patients and thus influence the analysis. Y Chromosome is removed because there are not enough male patients to make reliable statistical statements.

```{r, echo = TRUE}
## Removing chromosome X and Y.
    genes_data_frame <- data.frame(genes_data_framexy[!(genes_data_framexy$Chromosome == "chrX" | genes_data_framexy$Chromosome == "chrY"),])
    promoters_data_frame <-     data.frame(promoters_data_framexy[!(promoters_data_framexy$Chromosome == "chrX" | promoters_data_framexy$Chromosome == "chrY"),])
    remove(genes_data_framexy, promoters_data_framexy)
```

### Distribution of beta values by healty and AML patients.

> First we wanted to check wheather the distributions of beta values differ between AML and healty patients.  

```{r, echo = TRUE} 
## Creating dataframes for genes and prmoters with all beta values without NAs.
    g_AML_bedall <- data.frame(Beta = c(t(na.omit(genes_data_frame[,11:20]))))
    g_Mono_bedall <- data.frame(Beta = c(t(na.omit(genes_data_frame[,21:30]))))
## Transforming the above created dataframes into a data frame where coverage is the only variable.   
    p_AML_bedall <- data.frame(Beta = c(t(na.omit(promoters_data_frame[,11:20]))))
    p_Mono_bedall <- data.frame(Beta = c(t(na.omit(promoters_data_frame[,21:30]))))
```

#### Distribution of all beta values by AML or Mono patiens in the genes and promoters dataset.
```{r, echo = TRUE}
par(mfrow=c(1, 2))    
    hist(g_Mono_bedall$Beta, main = "Distribution beta Mono genes", xlab = "beta value", col = "forestgreen", breaks = 50, ylim = c(0, 80000))
    hist(g_AML_bedall$Beta, main = "Distribution beta AML genes", xlab = "beta value", col = "red", breaks = 50)
```  

```{r, echo = TRUE}
    par(mfrow=c(1, 2))    
    hist(p_Mono_bedall$Beta, main = "Distribution beta Mono promoters", xlab = "beta value", col = "forestgreen", breaks = 50, ylim = c(0, 80000))
    hist(p_AML_bedall$Beta, main = "Distribution beta AML promoters", xlab = "beta value", col = "red", breaks = 50)
```  

> It can be seen for both promoters and genes, that the two plots have a slightly different distribution.

### Removing unneccesary variables

> For the analysis we only need the beta and the coverage values of the patients.

```{r, echo=TRUE}
    g_patients <- data.frame(genes_data_frame[11:50])
    p_patients <- data.frame(promoters_data_frame[11:50])
```

### Setting coverage thresholds and handling NAs

> If a coverage value is too low that means there are not enough reads for given sequence. If it is too high however that might be due to overlapping of repeated sequences by the alignment.  This can render our analysis unreliable so we need to find sensible thresholds. The lower coverage threshold was set by 25 based on literature (Ziller et al., 2015). For the higher however we came up with the solution to find the value where we would loose the lowest percentage of data by loosing the highest percentage of coverage values. To check if this is even possible we made two plots to evalueate the function. Since the two datasets have a different distribution we need to find seperate upper thresholds.

> Once we find the threshold we will convert all beta values with an unrelaible corresponding coverage value to NAs. Next we will remove all rows with more than 3 NAs for one cohort.

#### Creating data frames with all coverage values by genes and promoters
```{r,  echo=TRUE} 
    g_coverage_all <- data.frame(Coverage = c(t(genes_data_frame[,31:50])))
    p_coverage_all <- data.frame(Coverage = c(t(promoters_data_frame[,31:50])))
```

#### Drawing a "if we make this the maximum coverage value we keep this % of objects" plot. 
```{r, echo = TRUE}
    Y = seq(0, 200000, 1)
## Calculating the coverage value for the given quantile (Y).
    Q = ecdf(g_coverage_all$Coverage) (Y)
## Plotting quntiles of the dataset against the quaniles for the coverage values by genes based on the previously explained g_coverage_all dataset. 
    plot(Y, Q, type = "n", main = "Quantiles for coverage values by genes", xlab = "Coverage value", ylab = "Quantile")
    lines(Y, Q)
```


```{r, echo = TRUE}
    Y = seq(0, 200000, 1)
## Calculating the coverage value for the given quantile (Y).
    Q = ecdf(p_coverage_all$Coverage) (Y)
  ## Plotting quntiles of the dataset against the quaniles for the coverage values by promoters based on the previously explained p_coverage_all dataset.
    plot(Y, Q, type = "n", main = "Quantiles for coverage values by promoters", xlab = "Coverage value", ylab = "Quantile")
    lines(Y, Q)
```

> The curves for both datasets have a very rapid increase by lower coverage values. So this confirms that we can use our above mentioned method and loose a very low percentage of data by cutting away a relatively high percentage of the maximum coverage value, so we can proceed with the analyis. 

### Finding the upper threshold - Ultraloop

> For finding the upper threshold we used the ultraloop. The ultraloop calculates the amount of lines which would remain if we were to cut at a given coverage value. The way the ultraloop works, is that it turnes the trustworthy values into NAs and cuts these rows away by a certain coverage threshold. The number of remaining rows is then substracted from the initial number of rows in the dataset. This way it gets faster at every iteration, because the size of the daset is significantly reduced. The output of the ultraloop is a dataset with number of genes/ promoters that would remain. This can be than plotted against the integrated sequences. Finally we can use a kneedle algorithm to find the highest curviture of the slope and define the thresholds. 
>
> First we want to create the sequence the ultraloop goes threw (g_sequence_ultraloop). It starts with 25 because this is our bottom threshold. We then took the 200 largest coverage vales from the genes dataset and created a sequence which goes from 25 up to the smallest from the top 200 values. Finally a vector was created with the sequence and the top 200 values combined and named g_sequence_ultraloop. Creatin this sequence was neccesary for the kneedle analysis to work properly. 

#### Creating the sequence for the ultraloop for genes.
```{r, echo=TRUE}
## Sorting the previously described g_coverage_all dataset in decreasing order. g_coverage all seq is defined as the 200 largest coverage values from the genes dataset. 
g_coverage_all_seq <- sort(g_coverage_all$Coverage, decreasing = TRUE)
g_coverage_all_seq <- g_coverage_all_seq[1:200]
g_coverage_all_seq <- sort(g_coverage_all_seq)

## The g_sequence_ultraloop starts at 25 and goes up to the smallest value of the g_coverage_all_seq dataset in steps of 100. Then is goes threw the 200 largest coverage values from the genes dataset. 
g_sequence_ultraloop <- c(seq(25, min(g_coverage_all_seq), 100), g_coverage_all_seq)
g_count <- floor(length(g_sequence_ultraloop)/100)
remove(g_coverage_all_seq)

plot(g_sequence_ultraloop, type = "l", main = "Sequence the ultraloop goes threw", xlab = "Count", ylab = "Coverage")
```

> We created the "analyse" dataset, which is used by the ultaloop. In this dataframe beta values with a corresponding coverage value <25 are set to NAs. 

#### Creating the analyse dataset and defining lower threshold as g_lowercov
```{r, echo=TRUE}
  ## Defing analyse dataset as g_patients initially. 
  analyse <- g_patients
  g_lowercov <- 25

  ## Separating data set
  analyse_bet <- analyse[, 1:20]
  analyse_cov <- analyse[, 21:40]
```

#### Setting the beta values with a corresponding coverge values >25 to NAs
```{r, echo=TRUE}  
  ## Using the ifelse functions to record which positions in coverage should be NA and setting those positions in beta to NA
  cov_NAs <- ifelse(analyse_cov < g_lowercov, 1, 0)
  analyse_bet[cov_NAs == 1] <- NA
```

#### Removing rows with more than 3 NAs
```{r, echo=TRUE}
  ## Recombining and cleaning data set
  analyse <- cbind(analyse_bet, analyse_cov)
  analyse <- analyse[!(rowSums(is.na(analyse[1:10])) > 3 | 
                         rowSums(is.na(analyse[11:20])) > 3),  ]
```

> At this point we need to change the NAs by the beta values to -1 and the NAs in beta to NAs by the coverage values. The reason is that in the ultraloop thrustworthy (smaller than the given coverage value) data will be set to NAs  and if the number of NAs is >6 for one cohort at least the row is cut away. Than the number of remaining rows is substracted from the initial number of rows to calculate the number of remaining genes that would remain if we used this coverge value as a threshold.

#### Setting the NAs to -1, by genes 
```{r, echo=TRUE}
  ## Separating data set again to beta values and coverage
  analyse_bet <- analyse[ , 1:20]
  analyse_cov <- analyse[, 21:40]
  
  ## Using ifelse to set NAs in beta to -1 and set NAs in beta to NA in coverage
  bet_NAs <- ifelse(is.na(analyse_bet), 1, 0 )
  analyse_bet[bet_NAs == 1] <- -1
  analyse_cov[bet_NAs == 1] <- NA

  ## Recombining and cleaning data set
  analyse <- cbind(analyse_bet, analyse_cov)

  ## Removing uneccesary data sets
  remove(analyse_cov, analyse_bet, cov_NAs, bet_NAs)
```

> The ultraloop goes threw the sequence "g_sequence_ultraloop" and creates the above described dataset.

#### Ultraloop for genes
```{r, echo=TRUE}
g_Ultraloop <- analyse
vector_remaining_genes_per_coverage <- c()
nrow_g <- nrow(g_Ultraloop)

for (y in g_sequence_ultraloop) {
  
  ## Defining separate dat sets and uppercov
  g_Ultraloop_bet <- g_Ultraloop[ , 1:20]
  g_Ultraloop_cov <- g_Ultraloop[ , 21:40]
  g_uppercov <- y
  
  ## Using the ifelse functions to record which positions in coverage are trustworthy and turning them into NA
  cov_NAs <- ifelse(g_Ultraloop_cov < g_uppercov, 1, 0 )
  g_Ultraloop_bet[cov_NAs == 1] <- NA
  
  ## Recombining the data set and cleaning out of trustworthy rows (>6 NAs), because these will be trustworthy on the next run through too
  g_Ultraloop <- cbind(g_Ultraloop_bet, g_Ultraloop_cov)
  g_Ultraloop <-
    g_Ultraloop[!(rowSums(is.na(g_Ultraloop[1:10])) > 6 &
                    rowSums(is.na(g_Ultraloop[11:20])) > 6) , ]

  ## Calculating from the deficit of rows how many would've remained and storing them
  g_cut <- (nrow_g - nrow(g_Ultraloop))
  vector_remaining_genes_per_coverage <-
    c(vector_remaining_genes_per_coverage, g_cut)
  
  if(g_cut == nrow_g) {
    break()
  }
}
```

#### Removing uneccesary data sets
```{r, echo=TRUE}
remove(y, g_Ultraloop, nrow_g, analyse, cov_NAs, g_cut, g_Ultraloop_bet, g_Ultraloop_cov, g_lowercov, g_uppercov)

```

> We conducted the exact same analysis for promoters, however the code is not shown for space saving purposes. Including the following steps

 * Creating neccesary datasets for the ultraloop for promoters.
 * Creating the analyse dataset and defining its variables for promoters.
 * Setting NAs to -1 by promoters.
 * Ultraloop code for promoters.

```{r, echo=FALSE}
## Sorting  the previously described p_coverage_all dataset in decreasing order.
p_coverage_all_seq <- sort(p_coverage_all$Coverage, decreasing = TRUE)
p_coverage_all_seq <- p_coverage_all_seq[1:200]
p_coverage_all_seq <- sort(p_coverage_all_seq)

## p will be the sequnce, that ultraloop goes threw
p <- c(seq(25, min(p_coverage_all_seq), 50), p_coverage_all_seq)
p_count <- floor(length(p)/100)
remove(p_coverage_all_seq)
```

```{r, echo=FALSE}
## creating the analyse data set and defining variables
analyse <- p_patients
p_lowercov <- 25

## Cleaning out rows with low coverage and separating data sets
analyse_bet <- analyse[ , 1:20]
analyse_cov <- analyse[, 21:40]

## Using the ifelse functions to record which positions in coverage should be NA and setting those positions in beta to NA
cov_NAs <- ifelse(analyse_cov < p_lowercov, 1, 0)
analyse_bet[cov_NAs == 1] <- NA

## Recombining and cleaning data set
analyse <- cbind(analyse_bet, analyse_cov)
analyse <- analyse[!(rowSums(is.na(analyse[1:10])) > 3 | 
                       rowSums(is.na(analyse[11:20])) > 3),  ]
```

```{r, echo=FALSE}
# Separating data set again
  analyse_bet <- analyse[ , 1:20]
  analyse_cov <- analyse[, 21:40]

# Using ifelse to set NAs in bet to -1 and set NAs in bet to NA in coverage
  bet_NAs <- ifelse(is.na(analyse_bet), 1, 0 )
  analyse_bet[bet_NAs == 1] <- -1
  analyse_cov[bet_NAs == 1] <- NA

# Recombining and cleaning data set
  analyse <- cbind(analyse_bet, analyse_cov)

# Removing uneccesary data sets
  remove(analyse_cov, analyse_bet, cov_NAs, bet_NAs)
```

```{r, echo=FALSE}
  ## p_Ultraloop is initially defined as the analyse funcion, and is then used by the loop
  p_Ultraloop <- analyse
  vector_remaining_promoters_per_coverage <- c()
  nrow_p <- nrow(p_Ultraloop)

for (y in p) {
  
  ## Defining separate dat sets and uppercov
  p_Ultraloop_bet <- p_Ultraloop[ , 1:20]
  p_Ultraloop_cov <- p_Ultraloop[ , 21:40]
  p_uppercov <- y
  
  ## Using the if-else functions to record which positions in coverage are trustworthy and turning them into NA
  cov_NAs <- ifelse(p_Ultraloop_cov < p_uppercov, 1, 0 )
  p_Ultraloop_bet[cov_NAs == 1] <- NA
  
  ## Recombining the data set and cleaning out of trustworthy rows (>6 NAs), because these will be trustworthy on the next run through too
  p_Ultraloop <- cbind(p_Ultraloop_bet, p_Ultraloop_cov)
  p_Ultraloop <-
    p_Ultraloop[!(rowSums(is.na(p_Ultraloop[1:10])) > 6 &
                    rowSums(is.na(p_Ultraloop[11:20])) > 6) , ]
  
  ## calculating from the deficit of rows how many would've remained and storing them
  p_cut <- (nrow_p - nrow(p_Ultraloop))
  vector_remaining_promoters_per_coverage <-
    c(vector_remaining_promoters_per_coverage, p_cut)
  
  if(p_cut == nrow_p) {
    break()
  }
}
  ## Removing uneccesary data sets
  remove(y, p_Ultraloop, nrow_p, analyse, cov_NAs, p_cut, p_Ultraloop_bet, p_Ultraloop_cov, p_lowercov, p_uppercov)
```

> Now we want to find the highest curviture of the function of the results. For this we used a code based on the kneedle algorithm. This code draws a line from the first point of the function to the last. Then the distance of the line from the function is calculated at each point and plotted. The peak of this new function delivers the highest curviture of slope. We than determine the coverage value in this point and set it as threshold.

#### Kneedle evaluation for genes

##### Obtaining the results of the ultraloop
```{r, echo=TRUE}
## Creating the g_UltraResults_NA3 dataframe 
  g_UltraResults_NA3 <- data.frame(vector_remaining_genes_per_coverage)
  g_sequence_ultraloop <- g_sequence_ultraloop[1:nrow(g_UltraResults_NA3)]
  g_UltraResults_NA3 <- cbind(g_UltraResults_NA3, g_sequence_ultraloop)
  g_UltraResults_NA3 <- data.frame(g_UltraResults_NA3)

  colnames(g_UltraResults_NA3) <- c("Remaining_Genes", "Coverage_Value")
```

##### Determining kneedle m
```{r, echo=TRUE}  
#Determining Kneelde m
  X2 <- max(g_UltraResults_NA3$Coverage_Value)
  X1 <- min(g_UltraResults_NA3$Coverage_Value)
  Y2 <- max(g_UltraResults_NA3$Remaining_Genes)
  Y1 <- min(g_UltraResults_NA3$Remaining_Genes)

  kneedle.m <- ((Y2-Y1)/(X2-X1))
```

##### Determining kneedle line and kneedle line to remaining gene count difference
```{r, echo=TRUE}
## Determining Kneedle Line, Kneedle Line to remaining gene count difference. 
  kneedle.line <- ((g_UltraResults_NA3$Coverage_Value-X1)*kneedle.m)
  g_UltraResults_NA3 <- cbind(g_UltraResults_NA3, kneedle.line)

  kneedle.difference <- (g_UltraResults_NA3$Remaining_Genes - g_UltraResults_NA3$kneedle.line)
## Cbinding of kneedle differece and ultraloop results.  
  g_UltraResults_NA3 <- cbind(g_UltraResults_NA3, kneedle.difference)
```

#### Plotting coverge values against ultraloop results with kneedle included for genes.
```{r, echo=TRUE}
  plot(g_UltraResults_NA3$Coverage_Value, g_UltraResults_NA3$Remaining_Genes, type = "n", xlab = "Upper coverage threshold", ylab = "Remaining rows", main = "Kneedle analysis genes")
  lines(g_UltraResults_NA3$Coverage_Value, g_UltraResults_NA3$Remaining_Genes)
  lines(g_UltraResults_NA3$Coverage_Value, g_UltraResults_NA3$kneedle.line)
  lines(g_UltraResults_NA3$Coverage_Value, g_UltraResults_NA3$kneedle.difference)

  remove(X1, X2, Y1, Y2, kneedle.difference, kneedle.line, g_sequence_ultraloop)
```


#### Determing the final values.
```{r, echo=TRUE}
## Getting coverage at the knee (highest cuvature)
  g_uppercov_row <- which.max(g_UltraResults_NA3[, 4])
  g_uppercov <- g_UltraResults_NA3[g_uppercov_row,2]

  remove(g_uppercov_row, g_count, kneedle.m)
  print(g_uppercov)
```


#### Kneedle analysis for promoters. 

> Again we used the same procedure for analysing promoters with the kneedle algorithm as genes and plotted the results.  

```{r, echo=FALSE}
#Formatting
p_UltraResults_NA3 <- data.frame(vector_remaining_promoters_per_coverage)
p <- p[1:nrow(p_UltraResults_NA3)]
p_UltraResults_NA3 <- cbind(p_UltraResults_NA3, p)
p_UltraResults_NA3 <- data.frame(p_UltraResults_NA3)

colnames(p_UltraResults_NA3) <- c("Remaining_Promoters", "Coverage_Value")

#Determining Kneelde m
X2 <- max(p_UltraResults_NA3$Coverage_Value)
X1 <- min(p_UltraResults_NA3$Coverage_Value)
Y2 <- max(p_UltraResults_NA3$Remaining_Promoters)
Y1 <- min(p_UltraResults_NA3$Remaining_Promoters) 

kneedle.m <- ((Y2-Y1)/(X2-X1))

#Determining Kneedle Line, Kneedle Line to remaining promoters count difference and cbinding
kneedle.line <- ((p_UltraResults_NA3$Coverage_Value-X1)*kneedle.m)
p_UltraResults_NA3 <- cbind(p_UltraResults_NA3, kneedle.line)

kneedle.difference <- (p_UltraResults_NA3$Remaining_Promoters - p_UltraResults_NA3$kneedle.line)
p_UltraResults_NA3 <- cbind(p_UltraResults_NA3, kneedle.difference)
```

#### Plotting coverge values against ultraloop results with kneedle included.
```{r, echo=FALSE}
plot(p_UltraResults_NA3$Coverage_Value, p_UltraResults_NA3$Remaining_Promoters, type = "n", xlab = "Upper coverage threshold", ylab = "Remaining rows", main = "Kneedle analysis promoters")
lines(p_UltraResults_NA3$Coverage_Value, p_UltraResults_NA3$Remaining_Promoters)
lines(p_UltraResults_NA3$Coverage_Value, p_UltraResults_NA3$kneedle.line)
lines(p_UltraResults_NA3$Coverage_Value, p_UltraResults_NA3$kneedle.difference)
```

#### Upper threshold for coverage values for promoters:
```{r, echo=FALSE}
remove(X1, X2, Y1, Y2, kneedle.difference, kneedle.line, p)

## Getting coverage at the knee
p_uppercov_row <- which.max(p_UltraResults_NA3[, 4])
p_uppercov <- p_UltraResults_NA3[p_uppercov_row,2]

remove(p_uppercov_row, p_count)
print(p_uppercov)
```


### Cleaning out unreliable rows with unreliable coverage and too many NAs

> Now that the thresholds are identified the beta values with a corresponding  coverage value <25 and > 98525 for genes will be set to NAs. For prmoters we used <25 and > 14175 as thresholds based on the kneedle analyisis as well.

#### Separating datasets and defining the threshold as variables 
````{r, echo=TRUE}
  # Separating our data set for ifelse application
  g_pat_bet <- g_patients[ , 1:20]
  g_pat_cov <- g_patients[, 21:40]
  
  p_pat_bet <- p_patients[ , 1:20]
  p_pat_cov <- p_patients[, 21:40]

  ## Defining upper and lower coverage values
  g_lowercov <- 25
  g_uppercov <- 98525
  
  p_lowercov <- 25
  p_uppercov <- 14175
```


#### Setting the unrelaible values to NAs based on the previously described variables
```{r, echo=TRUE}    
  ## Using the ifelse functions to record which positions in coverage should be NAs
  g_NAs <- ifelse(g_pat_cov < g_lowercov | g_pat_cov >= g_uppercov, 1, 0 )
  p_NAs <- ifelse(p_pat_cov < p_lowercov | p_pat_cov >= p_uppercov, 1, 0 )
  
  ## Turning those positions into NA
  g_pat_bet[g_NAs == 1] <- NA
  p_pat_bet[p_NAs == 1] <- NA
  
  ## Recombining our dataset
  g_pat_covNA <- cbind(g_pat_bet, g_pat_cov)
  p_pat_covNA <- cbind(p_pat_bet, p_pat_cov)
```

> Next the rows with more than 3 NAs for at least in one patient group will be removed since these genes or promoters are unrelaible. 

#### Leaving out rows that harbour cohorts with too many NAs
```{r, echo=TRUE}
  genes_clean <- g_pat_covNA[!(rowSums(is.na(g_pat_covNA[1:10])) > 3 | 
                                 rowSums(is.na(g_pat_covNA[11:20])) > 3),  ]
  
  promoters_clean <- p_pat_covNA[!(rowSums(is.na(p_pat_covNA[1:10])) > 3 | 
                                     rowSums(is.na(p_pat_covNA[11:20])) > 3),  ]
``` 

#### Removing uneccesary data sets
```{r, echo=TRUE} 
  remove(g_lowercov, g_uppercov, g_NAs, g_pat_bet, g_pat_cov, g_pat_covNA, g_patients)
  remove(p_lowercov, p_uppercov, p_NAs, p_pat_bet, p_pat_cov, p_pat_covNA, p_patients)

```


# Normalization 
> In oder to be able to perform a Student t-test later we need to nomalize the data. This was done by converting the beta values to M values. This has many advantages: M values are colse to a normal distribution, range from infinity to negative infinity and have a stable variance. 
Eqation for normaliuation: $M =\log_{2}(\frac{\beta}{1-\beta})$

### Code for normalization

#### Defining the function f_BetaToM, which converts the $\beta$ - values to M values 
```{r, echo=TRUE}
## Definng datasets only with patients after having removes untrustworty data
genes_clean_reduced <- genes_clean[,1:20]
promoters_clean_reduced <- promoters_clean[,1:20]

## Since 0 and 1 render inf or -inf as results we used 0.0000000001, 0.9999999999 respectively in the calculation instead.
f_BetaToM <- function(x) {
  
  if(!(is.na(x))){
    
    if(x == 1){
      x <- 0.9999999999
    }
    
    if(x == 0) {
      x <- 0.0000000001
    }
    
    x = log2(x / (1 - x))
  }
  
  return(x)
}
```

#### Applying f_BetatoM function on genes and promoters dataset.
```{r, echo=TRUE}
g_M_NA <- apply(genes_clean_reduced, c(1,2), f_BetaToM)
g_M_NA <- data.frame(g_M_NA)

p_M_NA <- apply(promoters_clean_reduced, c(1,2), f_BetaToM)
p_M_NA <- data.frame(p_M_NA)
```

# Imputation
> At this point still many NAs remain in the datassets, so we want to handle them. We could either get rid of all lines which still include NAs, or impute them. In order to keep as much information as possible we decided to impute the NAs. There are multiple models to do this and we tested out some on our data to find the best one. The reason we decided to impute after normalization is that if we were to do it before, the normalized means will differ from the means of the not-imputed M values. 

### Imputation models

[LEO's MAGIC]

### Code for replacing all NAs with rnorm10 imputation.
```{r, echo = TRUE}
## Defing the fg_rnorm10_imputation function.
fg_rnorm10_imputation <- function(x) {
  
  workingrow <- g_M_NA[x, ]
 
## If a row has more than 0 NAs they are replaced 
  if(rowSums(is.na(workingrow) > 0)) {
    replacement_positions <- which(is.na(workingrow))
    rowvalues <- workingrow[!(is.na(workingrow))]
    
    winnercandidates <- c(rep(0, (1+length(replacement_positions))))
    
    for(i in 1:10) {
      set.seed(x + nrow(g_M_NA)*i)
      rowextend <- c(rnorm(mean = mean(rowvalues), sd = sd(rowvalues), length(replacement_positions)))
      rowvalues_ext <- c(rowvalues, rowextend)
      
      preextendstats <- c(mean(rowvalues), sd(rowvalues))
      postextendstats <- c(mean(rowvalues_ext), sd(rowvalues_ext))
      impdiff <- (postextendstats-preextendstats)
      impdiff <- (sum(abs(impdiff)))
      
      candidate <- c(impdiff, rowextend)
      winnercandidates <- cbind(winnercandidates, candidate)
      
    }
    
    winnercandidates <- data.frame(winnercandidates)
    winnercandidates <- winnercandidates[, 2:ncol(winnercandidates)]
    winnercol <- which.min(winnercandidates[1, ])
    winner <- winnercandidates[2:nrow(winnercandidates), winnercol]
    
    workingrow[replacement_positions] <- winner
  }
  return(workingrow)
}

fp_rnorm10_imputation <- function(x) {
  
  workingrow <- p_M_NA[x, ]
  
  if(rowSums(is.na(workingrow) > 0)) {
    replacement_positions <- which(is.na(workingrow))
    rowvalues <- workingrow[!(is.na(workingrow))]
    
    winnercandidates <- c(rep(0, (1+length(replacement_positions))))
    
    for(i in 1:10) {
      set.seed(x + nrow(p_M_NA)*i)
      rowextend <- c(rnorm(mean = mean(rowvalues), sd = sd(rowvalues), length(replacement_positions)))
      rowvalues_ext <- c(rowvalues, rowextend)
      
      preextendstats <- c(mean(rowvalues), sd(rowvalues))
      postextendstats <- c(mean(rowvalues_ext), sd(rowvalues_ext))
      impdiff <- (postextendstats-preextendstats)
      impdiff <- (sum(abs(impdiff)))
      
      candidate <- c(impdiff, rowextend)
      winnercandidates <- cbind(winnercandidates, candidate)
      
    }
    
    winnercandidates <- data.frame(winnercandidates)
    winnercandidates <- winnercandidates[, 2:ncol(winnercandidates)]
    winnercol <- which.min(winnercandidates[1, ])
    winner <- winnercandidates[2:nrow(winnercandidates), winnercol]
    
    workingrow[replacement_positions] <- winner
  }
  return(workingrow)
}

j <- data.frame(seq(1, nrow(g_M_NA), 1))
jcount <- floor(nrow(j)/100)

g_Mvalues <- apply(j, c(1,2) , fg_rnorm10_imputation)
g_Mvalues <- matrix(unlist(g_Mvalues), ncol = nrow(g_M_NA), nrow = 20)
g_Mvalues <- data.frame(t(g_Mvalues))

j <- data.frame(seq(1, nrow(p_M_NA), 1))
jcount <- floor(nrow(j)/100)

p_Mvalues <- apply(j, c(1,2) , fp_rnorm10_imputation)
p_Mvalues <- matrix(unlist(p_Mvalues), ncol = nrow(p_M_NA), nrow = 20)
p_Mvalues <- data.frame(t(p_Mvalues))

## Recreating colnames and rownames.
colnames(g_Mvalues) <- colnames(g_M_NA)
rownames(g_Mvalues) <- rownames(g_M_NA)

colnames(p_Mvalues) <- colnames(p_M_NA)
rownames(p_Mvalues) <- rownames(p_M_NA)
## Removing the datasets that are no longer needed.
remove(j, jcount, genes_clean, genes_clean_reduced, promoters_clean, promoters_clean_reduced)

```

### Creating datasets (g_T and p_T) for the t-test with the neccesary information

#### Splitting datasets by patient cohorts.
```{r, echo=TRUE}
## Splitting datasets to AML and Mono
g_M_NA_AML <- g_M_NA[, 1:10]
g_M_NA_mon <- g_M_NA[, 11:20]

p_M_NA_AML <- p_M_NA[, 1:10]
p_M_NA_mon <- p_M_NA[, 11:20]
```

#### Defining the function f_MtoT

> The function f_MtoT will determine the values required for t-tests later. This includes mean value (m), standard deviation (sd) and number of NAs (n). 

```{r, echo=TRUE}
f_MtoT <- function(x) {
  
  
  m <- mean(x, na.rm = TRUE)
  sd  <- sd(x, na.rm = TRUE)
  n <- sum(!(is.na(x)))
  
  return(c(m,sd,n))
}
```

#### Application of f_MtoT to genes and promoters
```{r, echo=TRUE}
## Using the apply function to run f_MtoT
  g_T_AML <- t(apply(g_M_NA_AML, 1, f_MtoT))
  g_T_mon <- t(apply(g_M_NA_mon, 1, f_MtoT))

  p_T_AML <- t(apply(p_M_NA_AML, 1, f_MtoT))
  p_T_mon <- t(apply(p_M_NA_mon, 1, f_MtoT))
```

#### Naming and formatting the _T datasets
```{r, echo = TRUE}
## Naming and formatting the g_T and p_T datasets and removing the datasets that are no longer neccesary.
  g_T <- cbind(g_T_AML, g_T_mon)
colnames(g_T) <- c("Mean AML", "SD AML", "N AML", "Mean Mono", "SD Mono", "N Mono")
  g_T <- data.frame(g_T)

  p_T <- cbind(p_T_AML, p_T_mon)
colnames(p_T) <- c("Mean AML", "SD AML", "N AML", "Mean Mono", "SD Mono", "N Mono")
  p_T <- data.frame(p_T)
## Removing unneccesary datasets.
  remove(g_T_AML, g_T_mon, p_T_AML, p_T_mon, f_BetaToM, fg_rnorm10_imputation, fp_rnorm10_imputation, f_MtoT)
```

### Generating the resource dataset

> The resource dataset (g_Resource, p_Resource) includes the log2 foldchange, the ensembl ID and the symbols, if available, for genes and promoters each. This dataset is used later to search for the DMR suspects.
The foldchange describes how much the methylation changes among the patient groups in one row. It was calculated by first converting the mean m values back to $\beta$ in each row for one cohort. The reason is why we used the means is that in an M distribution the mean represents the most common i.e normal value from each patients cohort by promoters and genes. Then the newly gained $\beta$-values were devided as AML/Mono. Finally the log2 was calculted from the fraction.   

#### Collecting the mean values by genes and promoters for each patient cohort
```{r, echo=TRUE}
## Collecting the mean of the m values, as per the m distribution, the mean represents the most common i.e. normal value from each cohort by promoters or genes.
g_RM_AML_m <- data.frame(apply(g_M_NA_AML, 1, mean, na.rm = TRUE))
g_RM_mon_m <- data.frame(apply(g_M_NA_mon, 1, mean, na.rm = TRUE))

p_RM_AML_m <- data.frame(apply(p_M_NA_AML, 1, mean, na.rm = TRUE))
p_RM_mon_m <- data.frame(apply(p_M_NA_mon, 1, mean, na.rm = TRUE))
```

> Converting mean M values back to beta to be able to calculate the foldchange. For this we used the f_MtoBeta function. Equation: \beta =\frac{2^x}{1+2^x})$

#### Defining the f_MtoBeta function
```{r, echo=TRUE}
## Defining a function that converts the "normal" M value for each sequence's cohort to the corresponding "normal" beta value
f_MtoBeta <- function(x) {
  
  x = (2^x)/(1 + 2^x)
  return(x)
}
```

> Oddities of the data set resulting from application of the above funtion: if the original gene had a value of 1 for all samples in beta, the result here is 1, even though we changed those 1s to 0.999...9, so r has rounded here. However, genes that were 0 in bet are returned as 0.00...01 here, because we also changed them along the way. R has not rounded here. Very strange but coincidentally convenient for future formatting. Otherwise we wouldve had to set 0.9...9 to 1, and leave 0.0...1 because we can't divide by zero.

#### Applying the f_MtoBera on the means for each cohort by genes and promoters
```{r, echo=TRUE}
g_RB_AML_m <- apply(g_RM_AML_m, c(1,2), f_MtoBeta)
g_RB_mon_m <- apply(g_RM_mon_m, c(1,2), f_MtoBeta)
p_RB_AML_m <- apply(p_RM_AML_m, c(1,2), f_MtoBeta)
p_RB_mon_m <- apply(p_RM_mon_m, c(1,2), f_MtoBeta)
```

#### Calculating log2 foldchange and extracting symbols
```{r, echo=TRUE} 
## Calculating log2 foldchange from Mon to AML (so that the "normal" variety / 0 fold change is the healthy one)
g_RB_foldchange <- log2(g_RB_AML_m/g_RB_mon_m)
p_RB_foldchange <- log2(p_RB_AML_m/p_RB_mon_m)

## Extracting symbols for later from genes and promoters
g_R_Symbols <- data.frame(genes_data_frame$symbol)
rownames(g_R_Symbols) <- rownames(genes_data_frame)

p_R_Symbols <- data.frame(promoters_data_frame$symbol)
rownames(p_R_Symbols) <- rownames(promoters_data_frame)
```


#### Formatting the genes resource dataset
```{r, echo=TRUE}
## Formatting the g_resource data set: merging with foldchange and symbols
g_Resource <- merge(g_RB_foldchange, g_R_Symbols , by = 0, all = FALSE)
g_Resource <- g_Resource[, c(1,3,2)]
rownames(g_Resource) <- g_Resource$Row.names
colnames(g_Resource) <- c("Ensembl_ID", "Symbols", "Foldchange_Beta")

## Formatting the p_resource data set for promoters.
p_Resource <- merge(p_RB_foldchange, p_R_Symbols , by = 0, all = FALSE)
p_Resource <- p_Resource[, c(1,3,2)]
rownames(p_Resource) <- p_Resource$Row.names
colnames(p_Resource) <- c("Ensembl_ID", "Symbols", "Foldchange_Beta")
```

#### Removal of unneccesary datasets
```{r}
## Removal of uneccesary data sets
remove(g_M_NA_AML, g_M_NA_mon, g_R_Symbols, g_RB_AML_m, g_RB_mon_m, g_RB_foldchange, g_RM_AML_m, g_RM_mon_m, genes_data_frame, promoters_data_frame, f_MtoBeta)
remove(p_M_NA_AML, p_M_NA_mon, p_R_Symbols, p_RB_AML_m, p_RB_mon_m, p_RB_foldchange, p_RM_AML_m, p_RM_mon_m)
```